{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8fc343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import onnx\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7297ea07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/model1.pt\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join('models/','model{0}.pt'.format(0+1))\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8953edb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/model1.pt\n",
      "models/model2.pt\n",
      "models/model3.pt\n",
      "models/model4.pt\n",
      "models/model5.pt\n",
      "models/model6.pt\n",
      "models/model7.pt\n",
      "models/model8.pt\n",
      "models/model9.pt\n",
      "models/model10.pt\n",
      "models/model11.pt\n",
      "models/model12.pt\n",
      "models/model13.pt\n",
      "models/model14.pt\n",
      "models/model15.pt\n",
      "models/model16.pt\n",
      "models/model17.pt\n",
      "models/model18.pt\n",
      "models/model19.pt\n",
      "models/model20.pt\n",
      "models/model21.pt\n",
      "models/model22.pt\n",
      "models/model23.pt\n",
      "models/model24.pt\n",
      "models/model25.pt\n",
      "models/model26.pt\n",
      "models/model27.pt\n",
      "models/model28.pt\n",
      "models/model29.pt\n",
      "models/model30.pt\n",
      "models/model31.pt\n",
      "models/model32.pt\n",
      "models/model33.pt\n",
      "models/model34.pt\n",
      "models/model35.pt\n",
      "models/model36.pt\n",
      "models/model37.pt\n",
      "models/model38.pt\n",
      "models/model39.pt\n",
      "models/model40.pt\n",
      "models/model41.pt\n",
      "models/model42.pt\n",
      "models/model43.pt\n",
      "models/model44.pt\n",
      "models/model45.pt\n",
      "models/model46.pt\n",
      "models/model47.pt\n",
      "models/model48.pt\n",
      "models/model49.pt\n",
      "models/model50.pt\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    path = os.path.join('models/','model{0}.pt'.format(i+1))\n",
    "    print(path)\n",
    "    model = torch.load(path) #load the wieght of ur best model\n",
    "    model.to(torch.device(\"cpu\"))   # must u have to send the model to cpu\n",
    "def onnx_exporter(filename):\n",
    "    # if gpu:\n",
    "    #     model.to(T.device('cpu'))\n",
    "    model.eval()\n",
    "\n",
    "    torch.onnx.export(model, torch.ones([1, 1, 512, 1024]), 'onnx/' + filename + '.onnx', export_params=True, opset_version=9, do_constant_folding=True, input_names = ['input'], output_names = ['output'])\n",
    "\n",
    "    onnx.checker.check_model(onnx.load('onnx/' + filename + '.onnx'))\n",
    "\n",
    "    ort_session = onnxruntime.InferenceSession('onnx/' + filename + '.onnx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7737478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    onnx_exporter(\"output{}\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0074c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.avg = torch.nn.AvgPool2d(kernel_size = (3,3),stride = (2,2))\n",
    "            self.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels = 24,kernel_size = (7,7), stride = (2,2))  \n",
    "            self.bn1 = torch.nn.BatchNorm2d(24)\n",
    "            self.elu = torch.nn.ELU()\n",
    "            self.conv2 = torch.nn.Conv2d(in_channels=24, out_channels=36, kernel_size=(7,7), stride=(2, 2))  \n",
    "            self.bn2 = torch.nn.BatchNorm2d(36)\n",
    "            torch.nn.ELU()\n",
    "            self.conv3 = torch.nn.Conv2d(in_channels=36, out_channels=48, kernel_size=(5, 5), stride=(2, 2))\n",
    "            self.bn3 = torch.nn.BatchNorm2d(48)\n",
    "            torch.nn.ELU()\n",
    "            self.conv4 = torch.nn.Conv2d(in_channels=48, out_channels=64, kernel_size=(3,3), stride=(2,2))\n",
    "            self.bn4 = torch.nn.BatchNorm2d(64)\n",
    "            torch.nn.ELU()\n",
    "            self.conv5 = torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(2,2))  \n",
    "            self.bn5 = torch.nn.BatchNorm2d(64)\n",
    "            torch.nn.ELU()\n",
    "            self.conv6 = torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1))  \n",
    "            self.bn6 = torch.nn.BatchNorm2d(64)\n",
    "            torch.nn.ELU()\n",
    "            \n",
    "            self.dropout = torch.nn.Dropout(p=0.5)\n",
    "            self.linear1 = torch.nn.Linear(3072, 200)\n",
    "            torch.nn.ELU()\n",
    "            self.linear2 = torch.nn.Linear(200, 50)\n",
    "            torch.nn.ELU()\n",
    "            self.linear3 = torch.nn.Linear(50,10)\n",
    "            torch.nn.ELU()\n",
    "            self.linear4 = torch.nn.Linear(10,2)\n",
    "            \n",
    "        def forward(self,x):\n",
    "            x = self.avg(x)\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.elu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.bn2(x)\n",
    "            x = self.elu(x)\n",
    "            x = self.conv3(x)\n",
    "            x = self.bn3(x)\n",
    "            x = self.elu(x)\n",
    "            x = self.conv4(x)\n",
    "            x = self.bn4(x)\n",
    "            x = self.elu(x)\n",
    "            x = self.conv5(x)\n",
    "            x = self.bn5(x)\n",
    "            x = self.elu(x)\n",
    "            x = self.conv6(x)\n",
    "            x = self.bn6(x)\n",
    "            x = self.elu(x)\n",
    "           \n",
    "            x = x.reshape(-1,3072)\n",
    "            x = self.linear1(x)\n",
    "            x = self.elu(x)\n",
    "            x = self.linear2(x)\n",
    "            x = self.elu(x)\n",
    "            x = self.linear3(x)\n",
    "            x = self.elu(x)\n",
    "            x = self.linear4(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05994a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/final.pt\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join('models/','final.pt')\n",
    "print(path)\n",
    "model = torch.load(path) #load the wieght of ur best model\n",
    "model.to(torch.device(\"cpu\"))   # must u have to send the model to cpu\n",
    "def onnx_exporter(filename):\n",
    "    # if gpu:\n",
    "    #     model.to(T.device('cpu'))\n",
    "    model.eval()\n",
    "\n",
    "    torch.onnx.export(model, torch.ones([1, 1, 512, 1024]), 'onnx/' + filename + '.onnx', export_params=True, opset_version=9, do_constant_folding=True, input_names = ['input'], output_names = ['output'])\n",
    "\n",
    "    onnx.checker.check_model(onnx.load('onnx/' + filename + '.onnx'))\n",
    "\n",
    "    ort_session = onnxruntime.InferenceSession('onnx/' + filename + '.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e96b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_exporter(\"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd55d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hello_kernel",
   "language": "python",
   "name": "hello_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
